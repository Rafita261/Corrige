# ğŸ§  Challenge V â€“ Artificial Neural Network: Perceptron

## ğŸ“ Ã‰noncÃ©

Lâ€™un des fondements de lâ€™intelligence artificielle est le **rÃ©seau de neurones**, qui est composÃ© dâ€™unitÃ©s interconnectÃ©es appelÃ©es **neurones**.  
Un **perceptron** est le modÃ¨le le plus simple de neurone.

Chaque neurone contient :

- Des **entrÃ©es** : `inputs`
- Des **poids** : `weights`
- Un **biais** : `bias`
- Une **fonction dâ€™activation** : `f`
- Une **sortie** : `output`

---

## ğŸ“ Formule de calcul

Le calcul de la sortie se fait selon la formule :

```
output = f(Î£(inputs[i] * weights[i]) + bias)
```

Ensuite, on applique une **fonction dâ€™arrondi spÃ©ciale** pour respecter les contraintes de sortie.

---

## ğŸ§  Fonctions dâ€™activation possibles

| Fonction      | Nom dans lâ€™entrÃ©e | Description                            |
|---------------|------------------|----------------------------------------|
| IdentitÃ©      | `identity`       | f(x) = x                                |
| SigmoÃ¯de      | `sigmoid`        | f(x) = 1 / (1 + exp(-x))                |
| Heaviside     | `heaviside`      | f(x) = 0 si x < 0, sinon 1              |
| Tanh          | `tanh`           | f(x) = tanh(x)                          |
| ReLU          | `relu`           | f(x) = max(0, x)                        |

---

## ğŸ” Fonction d'arrondi spÃ©ciale

Afin de coller aux contraintes du sujet, les sorties doivent Ãªtre :

- Un **entier** si possible (ex. `3.00` devient `3`)
- Un **rÃ©el avec 1 ou 2 dÃ©cimales significatives**
- Si le rÃ©sultat est **proche de 0** (ex. `0.0009`), retourner `0`

### ğŸ”¢ Exemples dâ€™arrondi

| EntrÃ©e        | Sortie attendue |
|---------------|-----------------|
| 1.158696      | `1.16`          |
| 2.0000        | `2`             |
| -1.9999       | `-2`            |
| 0.00092       | `0`             |
| 3.10          | `3.1`           |

---

## ğŸ“¥ Format dâ€™entrÃ©e (STDIN)

```
n              â† nombre de tests
m              â† taille des vecteurs input et weight
inputs (m)     â† m entiers
weights (m)    â† m entiers
bias           â† entier
f              â† nom de la fonction dâ€™activation
(recommencer pour n tests)
```

---

## ğŸ“¤ Format de sortie

Un entier ou rÃ©el arrondi selon les rÃ¨gles, pour chaque test.

---

## âœ… Exemples

### ğŸ”¢ Input
```
2
3
1 1 1
1 2 3
1
identity
2
5 6
-2 1
1
relu
```

### ğŸ¯ Output
```
7
0
```

---

## ğŸ ImplÃ©mentation en Python

```python
import math

def Round(x):
    if x == int(x) or int(x)*100 == int(x*100):
        return int(x)
    if (x*10) == int(x*10):
        return round(x, 1)
    return round(x, 2)

def perceptron(inputs, weight, bias, f, m):
    o = bias
    for i in range(m):
        o += inputs[i] * weight[i]
    if f == "sigmoid":
        return Round(1 / (1 + math.exp(-o)))
    if f == "tanh":
        return Round(math.tanh(o))
    if f == "heaviside":
        return 0 if o < 0 else 1
    if f == "relu":
        return Round(max(0, o))
    return Round(o)

if __name__ == "__main__":
    n = int(input())
    for _ in range(n):
        m = int(input())
        inputs = list(map(int, input().split()))
        weights = list(map(int, input().split()))
        bias = int(input())
        f = input().strip().lower()
        print(perceptron(inputs, weights, bias, f, m))
```

---

ğŸ“‚ [â¬… Retour Ã  la liste des challenges](../)

---
